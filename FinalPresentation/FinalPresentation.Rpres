<style>
h1 {
font-family: "Comic Sans"
}
</style>

Time Series Interpolation Algorithms: Part 2
========================================================
author: Melissa Van Bussel
date: March 25th, 2019
autosize: false

Recall from last time...
========================================================

- A *time series* is a sequence of observations, $\{X_t\}$,  
one taken at each time $t$ and arranged in chronological order
- There are many methods available for modelling "nice" time series
- But...our data is not always nice

```{r, echo = FALSE, fig.align = "center", include = FALSE, fig.width = 12}
library(quantmod)
getSymbols("AMZN", from = "2008-08-01", to = "2008-09-01")
```

```{r, echo = FALSE, fig.align = "center", fig.width = 12, fig.height = 4}
dates <- seq(as.Date("2008-08-01"), 
             as.Date("2008-08-29"), 
             by = "days")
AMZNdf <- data.frame(dates = dates, 
                   close = rep(NA, length(dates)))
AMZN <- as.data.frame(AMZN)
for (i in 1:length(AMZNdf$dates)) {
  index <- which(rownames(AMZN) == AMZNdf$dates[i])
  if (length(index) != 0) {
    AMZNdf$close[i] <- AMZN$AMZN.Close[index]  
  }
}
plot(x = AMZNdf$dates, y = AMZNdf$close,
     main = "Amazon's Daily Closing Stock Price", 
     xlab = "Day",
     ylab = "Closing Price",
     type = "b")
```

Goals of this Honours Project
========================================================
- Research a variety of interpolation algorithms
- Test the algorithms on real-world data
- Evaluate the performance of the algorithms using a 
number of performance criteria

So...what would you do?
========================================================
- Let's brainstorm!
- Consider the following example, which we will use for
the next few slides: 
$$
\{X_t\} = \{4, 7, 9, \text{NA, NA}, 6, 3, 5, \text{NA}, 12, 15\}
$$

- How would you fill in those points?

```{r, echo=FALSE, fig.height = 3, fig.width = 12}
plot(c(4, 7, 9, NA, NA, 6, 3, 5, NA, 12, 15), ylab = "", type = "b")
```

Some Notation
========================================================
- We denote $x$ as the original time series, and $X$ as the
time series after the missing points have been interpolated
- There are many different algorithms; we will discuss a handful of them, briefly

Some Terrible Methods
========================================================
$$
\{X_t\} = \{4, 7, 9, \text{NA, NA}, 6, 3, 5, \text{NA}, 12, 15\}
$$

- Replace all missing values with a randomly generated 
number between the minimum value and maximum value of the
series
- Replace all missing values with the mean of the non-missing
values (or median, or mode)

Slightly less terrible, but still terrible...
========================================================
$$
\{X_t\} = \{4, 7, 9, \text{NA, NA}, 6, 3, 5, \text{NA}, 12, 15\}
$$
- Last Observation Carried Forward 
- Next Observation Carried Backward
- Nearest Neighbor

$$
X_i = \begin{cases} 
      x_A & i < \frac{a+b}{2} \\
      x_B & \text{otherwise} \\
   \end{cases}
$$

Linear Interpolation
========================================================
- Let $x$ be the original time series. Let $X$ be the 
series after interpolation. Then the linear interpolation
algorithm is as follows: 
$$
X_i = \frac{x_A - x_B}{a -b}(i - b) + x_B
$$

```{r, echo=FALSE, fig.height = 3, fig.width = 12}
library(zoo)
par(mfrow = c(1, 2))
x <- c(4, 7, 9, NA, NA, 6, 3, 5, NA, 12, 15)
X <- na.approx(x)
plot(x, main = "Missing Values", type = "b", ylab = "")
plot(X, main = "Linear Interpolation", type = "b", ylab = "")
```

Cubic Splines
========================================================
- For those of you that have taken 3180, this might be familiar!
- Cubic splines are interpolating polynomials
- Continuous cubic function connecting the endpoints of each sub-interval 
(piecewise defined)
- There are different "flavours" of cubic splines, based on boundary conditions

```{r, echo=FALSE, fig.height = 3, fig.width = 12}
library(zoo)
par(mfrow = c(1, 2))
x <- c(4, 7, 9, NA, NA, 6, 3, 5, NA, 12, 15)
X <- na.spline(x)
plot(x, main = "Missing Values", type = "b", ylab = "")
plot(X, main = "Natural Cubic Spline", type = "b", ylab = "")
```

Kalman Filters
========================================================
- The Kalman Filter is also sometimes known as the LQE Algorithm
- Step 1: Prediction step (estimates, with their uncertainties)
- Step 2: Update step (outcome of next observation measured; 
higher certainty = higher weights)
- Apollo navigation computer

```{r, echo=FALSE, fig.height = 3, fig.width = 12}
library(imputeTS)
par(mfrow = c(1, 2))
x <- c(4, 7, 9, NA, NA, 6, 3, 5, NA, 12, 15)
X <- na.kalman(x, model = "auto.arima")
plot(x, main = "Missing Values", type = "b", ylab = "")
plot(X, main = "Kalman Filter", type = "b", ylab = "")
```

Moving Averages
========================================================
- A "window" is created around the missing value, and a 
weighted average is computed
- Simple, Linear Weighted, Exponential Weighted
- Points which are closer to the missing observation are 
weighted more heavily 

$$
\{X_t\} = \{4, 7, 9, \text{NA, NA}, 6, 3, 5, \text{NA}, 12, 15\}
$$

Moving Averages 
========================================================

```{r, echo=FALSE, fig.width = 12}
library(imputeTS)
par(mfrow = c(2, 2))
x <- c(4, 7, 9, NA, NA, 6, 3, 5, NA, 12, 15)
X <- na.ma(x, weighting = "linear")
plot(x, main = "Missing Values", type = "b", ylab = "")
plot(X, main = "Simple Moving Average", type = "b", ylab = "")
plot(na.ma(x, weighting = "linear"), type = "b", 
           main = "Linear Weighted Moving Average",
           ylab = "")
plot(na.ma(x, weighting = "exponential"), type = "b", ylab = "",
           main = "Exponential Weighted Moving Average")
```

Hybrid Wiener Interpolator
========================================================

- An interpolator invented by our very own Wesley Burr!
- Can be generally thought of as an "EM algorithm"
- Step 1: **Expectation** Step (the autocovariance function 
of the process is estimated)
- Step 2: **Maximization** Step (estimation of the missing
values, using the estimate of the ACVF)

```{r, echo=FALSE, fig.height = 3, fig.width = 12, message = FALSE, warning = FALSE}
setwd("~/School/Trent/Fourth Year/MATH4800")
load("FinalPresentationData.RDa")
par(mfrow = c(1, 2))
plot(x, main = "Missing Values", type = "b", ylab = "")
plot(X, main = "Hybrid Wiener Interpolator", type = "b", ylab = "")
```

How can we evaluate the performance?
========================================================
- Now that we've seen a handful of algorithms, we need a way
to see how well they perform. 
- $r, r^2$, absolute differences, MBE, ME, MAE, MRE, MARE, 
MAPE, SSE, MSE, RMS, NMSE, RMSE, NRMSD, RMSS...to name a few.
- Let's focus on a couple. 

Coefficient of Correlation
========================================================
- How closely related are $x$ and $X$? 
- Ranges from -1 to +1, where +1 represents a perfectly positive correlation
and -1 represents a perfectly negative correlation

$$
r = \frac{\sum_{i = 1}^n(X_i - \bar{X})(x_i - \bar{x})}{\sqrt{\sum_{i=1}^n(X_i - \bar{X})^2} \sqrt{\sum_{i=1}^n(x_i - \bar{x})^2}}
$$ 

Mean Square Error 
========================================================
- Commonly referred to as MSE 
- The sum of the squared errors, scaled by $n$: 

$$
\mathbf{MSE} = \frac{1}{n} \sum_{i = 1}^n (X_i - x_i)^2
$$

Testing Out the Algorithms 
========================================================
- 5%, 10%, 15%, 20%, 25% gaps imposed on 3 real-world datasets
(no missing observations originally)
- 18 different interpolation algorithms used on each one 
- 17 performance criteria for each 
- Created tables which display the algorithms that performed BEST, 
for each of the 17 criteria, for each of the algorithms and datasets
- Created tables which display the algorithms that performed WORST 
for each of the 17 criteria, for each of the algorithms and datasets

The Datasets Used
=======================================================
- The `airquality` dataset, temperature variable 
- Daily measurements of temperature (in Fahrenheit) 
in New York, May to September 1973

```{r, echo = FALSE, fig.width = 12, fig.height = 4}
plot(airquality$Temp, type = "l",
     xlab = "Day", 
     ylab = "Temperature (Fahrenheit)",
     main = "Daily Temperature Measurements in NY")
```

The Datasets Used
=======================================================
- The `sunspots` dataset
- Monthly mean relative sunspot numbers from 1749 to 1983

```{r, echo = FALSE, fig.width = 12, fig.height = 4}
plot(sunspots, type = "l",
     xlab = "Year", 
     ylab = "Mean Relative Sunspot Number",
     main = "Monthly Sunspot Numbers")
```

The Datasets Used
=======================================================
- The `flux` dataset, Penticton 
- Daily noon solar flux measurements from Penticton, 
British Columbia

```{r, echo = FALSE, fig.width = 12, fig.height = 4}
library(tsinterp)
data(flux)
df <- data.frame("pent" = flux$PentOrig,
                "index" = 1:length(flux$PentOrig))
smoothed_pent <- loess(pent ~ index, data = df, span = 0.05)
smoothed_pent <- predict(smoothed_pent)
plot(flux$PentOrig, 
     main = "Daily Noon Solar Flux Measurements (Penticton)", 
     xlab = "Time (Year)", 
     ylab = "Noon Solar Flux (SFU)", 
     type = "l",
     xaxt = "n",
     col = rgb(0, 0, 1, 0.3),
     ylim = c(45, 500))
axis(side = 1, at = seq(0, 15251, length.out = 10),
     labels = round(seq(1966, 2008, length.out = 10)))
lines(smoothed_pent, col = rgb(0, 0, 1, 0.8), lty = 2)
legend("topright",
       legend = c("Actual", 
                  "Smoothed"),
       col = c(rgb(0, 0, 1, 0.5), 
               rgb(0, 0, 1, 0.8)),
       lty = c(1, 2))
```

Why these datasets?
========================================================
- Datasets are of varying length 
- Time intervals are varying 
- Non-Stationary
- And, being honest...my computer couldn't handle much more.

Results 
========================================================
- Example: "Best Performances" table for 20% gaps
- Need to demonstrate in RStudio 

```{r, message = FALSE, warning = FALSE, echo = FALSE}
#load("~/School/Trent/Fourth Year/MATH4800/Performances/best_performance_0.20.RDa")
#View(best_performance_0.20)
```

Results
========================================================
- "Worst Performances" table for 20% gaps
- Need to demonstrate in RStudio

```{r, message = FALSE, warning = FALSE, echo = FALSE}
#load("~/School/Trent/Fourth Year/MATH4800/Performances/worst_performance_0.20.RDa")
#View(worst_performance_0.20)
```

Results
=======================================================
- The algorithms that performed well performed very comparably 
- Example: correlation; 25% gaps
- Need to demonstrate in RStudio

```{r, message = FALSE, warning = FALSE, echo = FALSE}
#load("~/School/Trent/Fourth Year/MATH4800/Performances/performance_matrices_0.25.RDa")
#View(performance_matrices_0.25[[1]])
#look at sunspots column
```

Discussion of Results
=======================================================
- Some criteria (such as MBE) are ineffective / not useful 
- Replacing missing values with random numbers, means, medians,
or modes is a terrible idea (as expected)
- Exponential Weighted Moving Average and Kalman Filters 
performed particularly well 
- The algorithms which performed well performed VERY well,
and it was a close race
- Different algorithms will perform better for different time series

Next Steps 
======================================================
- Expand analysis to include more datasets (will
require more computational power)
- Experiment with varying gap lengths 
- Include datasets from a wide variety of fields

References
==========================================================

- Wesley S. Burr. Air Pollution and Health: Time Series Tools and Analysis. Queen's University, PhD thesis. 2012.

- Wesley S. Burr (2012). `tsinterp`: A Time Series Interpolation Package for `R`. R Package.

- Mathieu Lepot, Jean-Baptiste Aubin, and Francois H.L.R. Clemens. Interpolation in Time Series: An Introductive Overview of Existing Methods, Their Performance and Uncertainty Assessment. Water 2017, 9(10), 796.

- DataCamp. "Introduction to Time Series Analysis" and "ARIMA Modeling with R".

